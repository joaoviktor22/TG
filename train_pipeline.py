# -*- coding: utf-8 -*-
"""train_pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xlRHqGCi20917jbvmwBJ0uccmWmpHwOJ

#Imports
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# clone YOLOv5 repository
# %cd /content
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
!git reset --hard 886f1c03d839575afecb059accf74296fad395b6

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import shutil

import torch

from IPython.display import Image, clear_output  # to display images
from utils.google_utils import gdrive_download  # to download models/datasets

from IPython.core.magic import register_line_cell_magic

!pip install clodsa
from matplotlib import pyplot as plt
from clodsa.augmentors.augmentorFactory import createAugmentor
from clodsa.transformers.transformerFactory import transformerGenerator
from clodsa.techniques.techniqueFactory import createTechnique
import xml.etree.ElementTree as ET
import cv2
# %matplotlib inline

# install dependencies as necessary
!pip install -qr requirements.txt  # install dependencies (ignore errors)

# clear_output()
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))

"""#Gera Data Augmentation"""

# Commented out IPython magic to ensure Python compatibility.
def create_folder_with_images_and_labels(input_path):
#   %rm -rf '/content/imagens_e_anotacoes'
  os.mkdir("/content/imagens_e_anotacoes")

#   %cp $input_path$"images"/* /content/imagens_e_anotacoes
#   %cp $input_path$"labels"/* /content/imagens_e_anotacoes
  # for image_name,label_name in zip(os.listdir(input_path+"images"),os.listdir(input_path+"labels")):
  #   image_path = os.path.join(input_path+"images", image_name)
  #   label_path = os.path.join(input_path+"labels", label_name)
  #   shutil.copy(image_path, "/content/imagens_e_anotacoes")
  #   shutil.copy(label_path, "/content/imagens_e_anotacoes")


def define_augmentor(OUTPUT_PATH):
  PROBLEM = "detection"
  ANNOTATION_MODE = "yolo"
  INPUT_PATH = "/content/imagens_e_anotacoes"
  GENERATION_MODE = "linear"
  OUTPUT_MODE = "yolo"
  
  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,
                              OUTPUT_MODE,
                              GENERATION_MODE,
                              INPUT_PATH,
                              {"outputPath":OUTPUT_PATH})
  transformer = transformerGenerator(PROBLEM)
  return augmentor, transformer

def generate_augmented_set(input_path, dst_path="/content/train/", append_dataset=False):
  create_folder_with_images_and_labels(input_path)
  augmentor, transformer = define_augmentor("/content/augmented_images_yolo")
  
  #Manter Original
  none = createTechnique("none",{})
  augmentor.addTransformer(transformer(none))
  #Rotações
  for i in range(36):
    rotate = createTechnique("rotate", {"angle" : 30 + i*300/35})
    augmentor.addTransformer(transformer(rotate))
  #Flip Ver.
  vFlip = createTechnique("flip",{"flip":0})
  augmentor.addTransformer(transformer(vFlip))
  #Flip Hor.
  hFlip = createTechnique("flip",{"flip":1})
  augmentor.addTransformer(transformer(hFlip))
  #Flip HV
  hvFlip = createTechnique("flip",{"flip":-1})
  augmentor.addTransformer(transformer(hvFlip))
  # # #Blur
  # avgBlur =  createTechnique("average_blurring", {"kernel" : 11})
  # augmentor.addTransformer(transformer(avgBlur))
  # %rm -rf "/content/augmented_images_yolo"
  
#   %rm -rf "/content/augmented_images_yolo"
  augmentor.applyAugmentation()

#   %rm -rf $dst_path
  os.mkdir(dst_path)
  os.mkdir(dst_path + 'images')
  os.mkdir(dst_path + 'labels')  

#   %cp /content/augmented_images_yolo/*.jpg $dst_path$"images"
#   %cp /content/augmented_images_yolo/*.txt $dst_path$"labels"

  if append_dataset:
    for dataset in append_dataset:
      for image_name,label_name in zip(os.listdir(dataset+"images"),os.listdir(dataset+"labels")):
        image_path = os.path.join(dataset+"images", image_name)
        label_path = os.path.join(dataset+"labels", label_name)
        shutil.copy(image_path, dst_path + 'images')
        shutil.copy(label_path, dst_path + 'labels')

# input_path: path to dataset to be augmented
# append_dataset: path to other datasets to be joined. Default=False

#returns: augmented images + joined datasets, if exists. Stored in /content/train
# can take some minutes to run.

generate_augmented_set(input_path="/content/gdrive/MyDrive/Nucleos/Datasets/original/train/",
                       append_dataset=["/content/gdrive/MyDrive/Nucleos/Datasets/brightness_preproc/train/",
                        "/content/gdrive/MyDrive/Nucleos/Datasets/sequential_preproc/train/"])

print("Número de imagens: ")
!ls -1 /content/gdrive/MyDrive/Nucleos/Datasets/completo/train/images/*.jpg | wc -l
print("Número de anotações: ")
!ls -1 /content/gdrive/MyDrive/Nucleos/Datasets/completo/train/labels/*.txt | wc -l

"""#Cria splits para validação k-fold"""

# Commented out IPython magic to ensure Python compatibility.
#@title Gera N Splits


def create_n_folds(images_path, N=10):

  files = os.listdir(images_path)
  n = np.arange(len(files))
  np.random.shuffle(n)
  n_split = np.array_split(n,N)
  folds = np.empty(N,).tolist()
  for i in range(N):
    folds[i] = [files[j] for j in n_split[i]]
  return folds


def make_folders(N=10, dst="/content/cross_val"):
#   %rm -rf $dst
  os.mkdir(dst)
  for i in range(N):
    folder = dst + "/split" + str(i+1)
    os.mkdir(folder)
    os.mkdir(folder + "/train")
    os.mkdir(folder + "/test")
    os.mkdir(folder + "/train/images")
    os.mkdir(folder + "/train/labels")
    os.mkdir(folder + "/test/images")
    os.mkdir(folder + "/test/labels")


def copy_image_by_image(ROOT, folds, i, j, idx=True, dst="/content/cross_val"):
  folder = ["/test", "/train"]
  dest_folder = dst + "/split" + str(i+1) + folder[idx]
  
  for image_name in folds[j]:
    image_path = ROOT + image_name
    label_path = ROOT.split("/images")[0] + "/labels/" + image_name.split(".jpg")[0] + ".txt"
    shutil.copy(image_path, dest_folder+"/images")
    shutil.copy(label_path, dest_folder+"/labels")


def create_n_splits(images_path, N=10, dst="/content/cross_val"):
  folds = create_n_folds(images_path, N)
  make_folders(N, dst=dst)
  for i in range(N):
    for j in range(N):
      if i == j:
        copy_image_by_image(images_path, folds, i, j, idx=False, dst=dst)
      else:
        copy_image_by_image(images_path, folds, i, j, dst=dst)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# %cd ../
# N = 5
# #path to images
# dataset_dir = "/content/train/images/"
# create_n_splits(dataset_dir, N)

"""##Checagem por desencargo de consciência"""

splits_path = "/content/gdrive/MyDrive/Nucleos/Datasets/completo/cross_val/"

for i in range(N):
  print("Split", i, " =====> Imagens de treino:",len(os.listdir(splits_path + "split"+str(i+1)+"/train/images")),
        "Imagens de teste:",len(os.listdir(splits_path + "split"+str(i+1)+"/test/images")))

repeated = []

for i in range(1, 6):
  splitfolder = splits_path + "split" +str(i)
  train = os.listdir(splitfolder + "/train/images")
  test = os.listdir(splitfolder + "/test/images")
  [repeated.append(x) for x in train if x in test]
  if any(repeated):
    print("Repeated imagens on split: ", i)
if not any(repeated):
  print("None repeated image in splits.")

"""#Inicia Treinamento"""

!nvidia-smi

isDataAug = True
cfg = ["original", "completo"]
path = "/content/gdrive/MyDrive/Nucleos/tmp/data_yaml/"
folder = path + cfg[isDataAug]
for file_name in os.listdir(folder):
  file_path = os.path.join(folder, file_name)
  shutil.copy(file_path, "/content/")

# Commented out IPython magic to ensure Python compatibility.
PRE_TRAIN = [True, False]
DEST_DIR_SPLITS = "/content/gdrive/MyDrive/Nucleos/CVal/"
DEST_DIR_RETRAIN = "/content/gdrive/MyDrive/Nucleos/Retreino/"
versions_list = ["s", "m", "l", "x"]


def check_train_config(PT_WEIGHTS, version):
  weight = None
  name = "v5" + version
  mdl = "./models/yolov5" + version + ".yaml"
  if PT_WEIGHTS:
    name = name + "w"
    weight = "yolov5" + version + ".pt"
  if isDataAug:
    name = name + "d"

  return name, weight, mdl


def check_lines_in_results(filename):
  if os.path.exists(filename):
    file = open(filename, "r")
    line_count = 0
    for line in file:
        if line != "\n":
            line_count += 1

    file.close()
    if line_count==200:
      return True
  
  return False


def train_splits(n_splits):
  for PT_WEIGHTS in PRE_TRAIN:
    for version in versions_list:
      name, weight, mdl = check_train_config(PT_WEIGHTS, version)
      
      for i in range(1, n_splits+1):
        name_s = name + str(i)
        data_s = "../split" + str(i) + ".yaml"
        if os.path.isdir(DEST_DIR_SPLITS + name_s):
          print("Train configuration already stored. Available on: ",DEST_DIR_SPLITS + name_s)
          continue
        
#         %cd /content/yolov5/
        !python train.py --img 416 --batch 4 --epochs 200 --data $data_s --cfg $mdl --weights $weight --cache  --name $name_s
        
        results_path = "/content/yolov5/runs/train/" + name_s 
        results_txt = os.path.join(results_path, "results.txt")
        if check_lines_in_results(results_txt):
          shutil.copytree(results_path, DEST_DIR_SPLITS + name_s)
      
      name = name + "r"
      if os.path.isdir(DEST_DIR_RETRAIN + name):
          print("Train configuration already stored. Available on: ",DEST_DIR_RETRAIN + name)
          continue
      data_r = "../data.yaml"
      
#       %cd /content/yolov5/
      !python train.py --img 416 --batch 4 --epochs 200 --data $data_r --cfg $mdl --weights $weight  --cache --name $name
      
      results_path = "/content/yolov5/runs/train/" + name 
      results_txt = os.path.join(results_path, "results.txt")
      if check_lines_in_results(results_txt):
        shutil.copytree(results_path, DEST_DIR_RETRAIN + name)

train_splits(n_splits=5)

# Commented out IPython magic to ensure Python compatibility.
# %rm -rf /content/yolov5/runs/train

src = "/content/gdrive/MyDrive/Podocitos/CVal"
for dir in os.listdir(src):
  dir = os.path.join(src, dir)
  filename = os.path.join(dir, "weights")
  if os.path.exists(filename):
    print(filename, " removed.")
    shutil.rmtree(filename)